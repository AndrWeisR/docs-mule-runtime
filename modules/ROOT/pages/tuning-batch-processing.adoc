= Batch Processing
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

Mule runtime engine (Mule) possesses the ability to process messages in batches. Within an application, you can initiate a batch job which is a block of code that splits large messages into individual records, performs actions upon each record, then reports on the results and potentially pushes the processed output to other systems or queues.

Consider having 1 million records processed by a batch application with three steps. Several I/O operations occur as Mule processes each record while they move through the jobâ€™s phases. The disk characteristics, along with the workload size, play a key role in the performance of the batch job. Mainly, because during the input phase, an in-disk queue is created with the list of records to be processed, which is constantly read and written by the flow resulting in heavy I/O utilization.

Additionally, batch processing requires having enough available memory to process the threads in parallel, which means moving the records from persistent storage into RAM in a fixed size block. The larger your records and their quantity, the more available memory you need for batch processing.

== Batch Block Size
By default, the batch block size is set to 100. It is a good balancing point between performance and working memory requirements based on analysis across a set of representative batch use cases with various record sizes. However, the optimal value for each application depends on its use case. +
You can configure this property for the batch job. If you believe that in your particular case, custom size is best suited, make sure to run comparative tests with different values to find the optimum size in your use case. The following example shows the batch block size:

[source,xml,linenums]
----
<batch:job jobName="test-batch" blockSize="${batch.block.size}">
----

To take full advantage of this feature, you must understand how the block sizes affect your batch job. Running comparative tests with different values and testing performance helps you find an optimum block size before deploying this change into production.

== See Also
* xref:batch-processing-concept.adoc[Batch Processing]
